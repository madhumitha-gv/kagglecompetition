{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":12186462,"sourceType":"datasetVersion","datasetId":7675760},{"sourceId":12307775,"sourceType":"datasetVersion","datasetId":7757709}],"dockerImageVersionId":31042,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 1. Install Transformers (if not already installed)\n!pip install transformers","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GVRv2L0fZQfs","outputId":"d82d886e-5882-4ba4-c445-a6cd44e94532","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install transformers datasets accelerate peft -q","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install --upgrade pip","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#Importing required libraries","metadata":{"id":"0dutDrdvadYi"}},{"cell_type":"code","source":"from transformers import AutoTokenizer,AutoModelForCausalLM, BitsAndBytesConfig","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":198},"id":"sQ_0Dw1YaefX","outputId":"0c3a599e-5c43-4f0f-c74b-e556baccc4f5","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install transformers accelerate peft","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nprint(\"Pandas version:\", pd.__version__)\nprint(\"Numpy version:\", np.__version__)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nprint(os.path.exists(\"/kaggle/input/clinical-reasoning-dataset/train.csv\"))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\ntrain_df = pd.read_csv(\"/kaggle/input/clinical-reasoning-dataset/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/clinical-reasoning-dataset/test.csv\")","metadata":{"id":"S1xOOBrFarKI","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ntrain_df.drop('Master_Index', axis=1, inplace=True) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.isnull().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nsns.histplot(data=train_df, x='Years of Experience')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"median_exp = train_df[\"Years of Experience\"].median()\ntrain_df[\"Years of Experience\"] = train_df[\"Years of Experience\"].fillna(median_exp)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.isnull().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_context(row):\n    return (\n        f\"County: {row['County']}, \"\n        f\"Health level: {row['Health level']}, \"\n        f\"Years of Experience: {row['Years of Experience']}, \"\n        f\"Nursing Competency: {row['Nursing Competency']}, \"\n        f\"Clinical Panel: {row['Clinical Panel']}\"\n    )\n\ntrain_df[\"Context\"] = train_df.apply(build_context, axis=1)\n\n# Construct the final SLM input prompt\ntrain_df[\"Input\"] = \"Context: \" + train_df[\"Context\"] + \"\\nPrompt: \" + train_df[\"Prompt\"]\n\n# Define target output\ntrain_df[\"Target\"] = train_df[\"Clinician\"]\n\n# Drop rows where Target is missing\ntrain_df = train_df[train_df[\"Target\"].notna()]\n\n# Save for training\ntrain_df[[\"Input\", \"Target\"]].to_csv(\"formatted_train_data.csv\", index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# example prompt","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\nmodel_id = \"google/flan-t5-small\"\n\n# Load model\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n\n# Define prompt\nprompt = \"\"\"\nContext: County: Kisumu, Health level: Level 3, Years of Experience: 10, Nursing Competency: High\nPrompt: A 22-year-old woman presents with fever, abdominal pain, and delayed menstruation.\nWhat would the clinician do?\n\"\"\"\n\n# Tokenize\ninputs = tokenizer(prompt, return_tensors=\"pt\")\n\n# Generate\noutputs = model.generate(**inputs, max_new_tokens=100)\n\n# Decode and print\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install transformers datasets accelerate\n\nimport pandas as pd\nfrom datasets import Dataset\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSeq2SeqLM,\n    DataCollatorForSeq2Seq,\n    Trainer,\n    TrainingArguments,\n)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 1: Load your formatted dataset\n# Check first if the file exists\nimport os\n\nif os.path.exists(\"/kaggle/input/input-output-formatted-csv/formatted_train_data.csv\"):\n    train_df_clean = pd.read_csv(\"/kaggle/input/input-output-formatted-csv/formatted_train_data.csv\")\n    print(\"Loaded successfully.\")\nelse:\n    print(\"File not found. Please ensure it was written in a previous step.\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import Dataset\n\n# Convert your cleaned DataFrame to a Hugging Face Dataset\ntrain_dataset = Dataset.from_pandas(train_df_clean[[\"Input\", \"Target\"]])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 2: Load FLAN-T5 tokenizer and model\nmodel_name = \"google/flan-t5-small\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install transformers datasets accelerate\n\nimport pandas as pd\nfrom datasets import Dataset\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSeq2SeqLM,\n    DataCollatorForSeq2Seq,\n    Trainer,\n    TrainingArguments,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"max_input_length = 512\nmax_target_length = 128\n\ndef preprocess(example):\n    model_input = tokenizer(\n        example[\"Input\"],\n        max_length=max_input_length,\n        truncation=True,\n        padding=\"max_length\",\n    )\n    labels = tokenizer(\n        example[\"Target\"],\n        max_length=max_target_length,\n        truncation=True,\n        padding=\"max_length\",\n    )\n    model_input[\"labels\"] = labels[\"input_ids\"]\n    return model_input\n\ntokenized_dataset = train_dataset.map(preprocess, batched=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import transformers\nprint(transformers.__version__)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import TrainingArguments","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -U transformers\nfrom transformers import TrainingArguments","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir=\"./flan-t5-clinician\",\n    evaluation_strategy=\"no\",  # or \"steps\" / \"epoch\"\n    per_device_train_batch_size=8,\n    num_train_epochs=3,\n    save_total_limit=1,\n    save_steps=500,\n    logging_dir=\"./logs\",\n    logging_steps=100,\n    fp16=False,\n    report_to=\"none\"\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import TrainingArguments\n\nargs = TrainingArguments(\n    output_dir=\"./test-model\",\n    per_device_train_batch_size=2,\n    num_train_epochs=1,\n    evaluation_strategy=\"epoch\",  # <-- should not error\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import TrainingArguments\nprint(TrainingArguments.__module__)\nprint(TrainingArguments.__doc__)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -U transformers --quiet","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import TrainingArguments\n\nprint(TrainingArguments.__module__)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import TrainingArguments\n\nargs = TrainingArguments(\n    output_dir=\"./test-model\",\n    per_device_train_batch_size=2,\n    num_train_epochs=1,\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nprint(os.listdir())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import transformers\nprint(transformers.__file__)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -U transformers --quiet\n\nfrom transformers import TrainingArguments\n\nprint(TrainingArguments.__module__)  # Should say transformers.training_args\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"args = TrainingArguments(\n    output_dir=\"./test-model\",\n    per_device_train_batch_size=2,\n    num_train_epochs=1,\n    evaluation_strategy=\"epoch\",\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(transformers.__file__)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip uninstall -y transformers\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install transformers==4.51.3 --force-reinstall --no-cache-dir\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import TrainingArguments\n\nargs = TrainingArguments(\n    output_dir=\"./test-model\",\n    per_device_train_batch_size=2,\n    num_train_epochs=1,\n    evaluation_strategy=\"epoch\",  # <-- this must now work\n)\n\nprint(\"âœ… Success!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}