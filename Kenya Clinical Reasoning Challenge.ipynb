{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12186462,"sourceType":"datasetVersion","datasetId":7675760}],"dockerImageVersionId":31042,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 1. Install Transformers (if not already installed)\n!pip install transformers","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GVRv2L0fZQfs","outputId":"d82d886e-5882-4ba4-c445-a6cd44e94532","trusted":true,"execution":{"iopub.status.busy":"2025-06-18T01:51:24.712752Z","iopub.execute_input":"2025-06-18T01:51:24.713380Z","iopub.status.idle":"2025-06-18T01:51:27.794599Z","shell.execute_reply.started":"2025-06-18T01:51:24.713339Z","shell.execute_reply":"2025-06-18T01:51:27.793822Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"!pip install transformers datasets accelerate peft -q\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T01:48:27.523914Z","iopub.execute_input":"2025-06-18T01:48:27.524163Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m0:01\u001b[0mm\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"#Importing required libraries","metadata":{"id":"0dutDrdvadYi"}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":198},"id":"sQ_0Dw1YaefX","outputId":"0c3a599e-5c43-4f0f-c74b-e556baccc4f5","trusted":true,"execution":{"iopub.status.busy":"2025-06-18T01:51:37.702031Z","iopub.execute_input":"2025-06-18T01:51:37.702809Z","iopub.status.idle":"2025-06-18T01:51:37.707552Z","shell.execute_reply.started":"2025-06-18T01:51:37.702770Z","shell.execute_reply":"2025-06-18T01:51:37.706511Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"!pip install transformers accelerate peft","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nprint(\"Pandas version:\", pd.__version__)\nprint(\"Numpy version:\", np.__version__)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T01:53:36.465282Z","iopub.execute_input":"2025-06-18T01:53:36.466012Z","iopub.status.idle":"2025-06-18T01:53:36.470380Z","shell.execute_reply.started":"2025-06-18T01:53:36.465988Z","shell.execute_reply":"2025-06-18T01:53:36.469572Z"}},"outputs":[{"name":"stdout","text":"Pandas version: 2.2.3\nNumpy version: 1.26.4\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import os\nprint(os.path.exists(\"/kaggle/input/clinical-reasoning-dataset/train.csv\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T01:53:40.195061Z","iopub.execute_input":"2025-06-18T01:53:40.195605Z","iopub.status.idle":"2025-06-18T01:53:40.210939Z","shell.execute_reply.started":"2025-06-18T01:53:40.195582Z","shell.execute_reply":"2025-06-18T01:53:40.210377Z"}},"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset\n\ntrain_df = pd.read_csv(\"/kaggle/input/clinical-reasoning-dataset/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/clinical-reasoning-dataset/test.csv\")\n","metadata":{"id":"S1xOOBrFarKI","trusted":true,"execution":{"iopub.status.busy":"2025-06-18T02:26:13.832351Z","iopub.execute_input":"2025-06-18T02:26:13.833047Z","iopub.status.idle":"2025-06-18T02:26:13.905443Z","shell.execute_reply.started":"2025-06-18T02:26:13.833027Z","shell.execute_reply":"2025-06-18T02:26:13.904870Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T02:26:15.377616Z","iopub.execute_input":"2025-06-18T02:26:15.378194Z","iopub.status.idle":"2025-06-18T02:26:15.386923Z","shell.execute_reply.started":"2025-06-18T02:26:15.378175Z","shell.execute_reply":"2025-06-18T02:26:15.386148Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 400 entries, 0 to 399\nData columns (total 12 columns):\n #   Column               Non-Null Count  Dtype  \n---  ------               --------------  -----  \n 0   Master_Index         400 non-null    object \n 1   County               400 non-null    object \n 2   Health level         400 non-null    object \n 3   Years of Experience  300 non-null    float64\n 4   Prompt               400 non-null    object \n 5   Nursing Competency   400 non-null    object \n 6   Clinical Panel       400 non-null    object \n 7   Clinician            400 non-null    object \n 8   GPT4.0               400 non-null    object \n 9   LLAMA                400 non-null    object \n 10  GEMINI               400 non-null    object \n 11  DDX SNOMED           399 non-null    object \ndtypes: float64(1), object(11)\nmemory usage: 37.6+ KB\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"train_df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T02:26:18.570700Z","iopub.execute_input":"2025-06-18T02:26:18.570967Z","iopub.status.idle":"2025-06-18T02:26:18.576309Z","shell.execute_reply.started":"2025-06-18T02:26:18.570949Z","shell.execute_reply":"2025-06-18T02:26:18.575516Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"Index(['Master_Index', 'County', 'Health level', 'Years of Experience',\n       'Prompt', 'Nursing Competency', 'Clinical Panel', 'Clinician', 'GPT4.0',\n       'LLAMA', 'GEMINI', 'DDX SNOMED'],\n      dtype='object')"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"train_df_2 = train_df[['Prompt', 'Clinician']].dropna().rename(columns={'Prompt': 'input', 'Clinician': 'output'})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T02:26:54.831557Z","iopub.execute_input":"2025-06-18T02:26:54.832298Z","iopub.status.idle":"2025-06-18T02:26:54.838227Z","shell.execute_reply.started":"2025-06-18T02:26:54.832277Z","shell.execute_reply":"2025-06-18T02:26:54.837451Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"train_dataset_2 = Dataset.from_pandas(train_df_2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T02:26:55.734037Z","iopub.execute_input":"2025-06-18T02:26:55.734361Z","iopub.status.idle":"2025-06-18T02:26:55.745841Z","shell.execute_reply.started":"2025-06-18T02:26:55.734341Z","shell.execute_reply":"2025-06-18T02:26:55.745145Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n\ndef preprocess(example):\n    return tokenizer(\n        [\"clinical prompt: \" + x for x in example[\"input\"]],\n        text_target=example[\"output\"],\n        truncation=True,\n        padding=\"max_length\",\n        max_length=512\n    )\n\ntokenized_train_2 = train_dataset_2.map(preprocess, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T02:27:11.477510Z","iopub.execute_input":"2025-06-18T02:27:11.478046Z","iopub.status.idle":"2025-06-18T02:27:12.084429Z","shell.execute_reply.started":"2025-06-18T02:27:11.478023Z","shell.execute_reply":"2025-06-18T02:27:12.083619Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/400 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df16acb1ea664d4490809770807124ee"}},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\").to(\"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T02:30:41.943200Z","iopub.execute_input":"2025-06-18T02:30:41.943762Z","iopub.status.idle":"2025-06-18T02:30:42.517569Z","shell.execute_reply.started":"2025-06-18T02:30:41.943740Z","shell.execute_reply":"2025-06-18T02:30:42.517009Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer, DataCollatorForSeq2Seq\nimport torch\n\ntraining_args = TrainingArguments(\n    output_dir=\"./finetuned-flan-t5-reasoning\",\n    per_device_train_batch_size=4,\n    num_train_epochs=5,\n    learning_rate=5e-5,\n    fp16=torch.cuda.is_available(),\n    logging_steps=10\n)\n\n\nfrom transformers import Trainer, DataCollatorForSeq2Seq\n\n# Re-initialize the trainer with same config\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    tokenizer=tokenizer,\n    data_collator=DataCollatorForSeq2Seq(tokenizer, model=model)\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T04:01:31.577828Z","iopub.execute_input":"2025-06-18T04:01:31.578534Z","iopub.status.idle":"2025-06-18T04:01:31.617105Z","shell.execute_reply.started":"2025-06-18T04:01:31.578510Z","shell.execute_reply":"2025-06-18T04:01:31.616348Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/2291468295.py:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"test_df = pd.read_csv(\"/kaggle/input/clinical-reasoning-dataset/test.csv\")  # update with correct path\ntest_df = test_df[['Prompt']].dropna().reset_index(drop=True)\n\n# Wrap into Hugging Face Dataset\ntest_dataset = Dataset.from_pandas(test_df.rename(columns={'Prompt': 'input'}))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T04:01:35.292763Z","iopub.execute_input":"2025-06-18T04:01:35.293018Z","iopub.status.idle":"2025-06-18T04:01:35.327320Z","shell.execute_reply.started":"2025-06-18T04:01:35.293000Z","shell.execute_reply":"2025-06-18T04:01:35.326640Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"def preprocess(example):\n    return tokenizer(\n        [\"clinical prompt: \" + x for x in example[\"input\"]],\n        truncation=True,\n        padding=\"max_length\",\n        max_length=512\n    )\n\ntokenized_test_dataset = test_dataset.map(preprocess, batched=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T04:01:37.597033Z","iopub.execute_input":"2025-06-18T04:01:37.597334Z","iopub.status.idle":"2025-06-18T04:01:37.658920Z","shell.execute_reply.started":"2025-06-18T04:01:37.597315Z","shell.execute_reply":"2025-06-18T04:01:37.658154Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"337bceb1c55046089fe5a05f23cd4c78"}},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"# Generate predictions from raw prompts using model.generate\nfrom tqdm import tqdm\n\n# Add prediction column to test DataFrame\ngenerated_responses = []\n\nfor prompt in tqdm(test_df['Prompt']):\n    input_text = \"clinical prompt: \" + prompt\n    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512).to(model.device)\n    \n    output_ids = model.generate(\n        input_ids=inputs[\"input_ids\"],\n        attention_mask=inputs[\"attention_mask\"],\n        max_new_tokens=100,\n        num_beams=4,\n        early_stopping=True\n    )\n    \n    decoded = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n    generated_responses.append(decoded)\n\n# Attach to test DataFrame and save\ntest_df['generated_response'] = generated_responses\ntest_df.to_csv(\"flan_t5_predictions.csv\", index=False)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T04:02:47.303539Z","iopub.execute_input":"2025-06-18T04:02:47.304012Z","iopub.status.idle":"2025-06-18T04:03:13.149818Z","shell.execute_reply.started":"2025-06-18T04:02:47.303992Z","shell.execute_reply":"2025-06-18T04:03:13.149127Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 100/100 [00:25<00:00,  3.87it/s]\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"# Attach to test DataFrame and save\ntest_df.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T04:03:53.954617Z","iopub.execute_input":"2025-06-18T04:03:53.955077Z","iopub.status.idle":"2025-06-18T04:03:53.971899Z","shell.execute_reply.started":"2025-06-18T04:03:53.955057Z","shell.execute_reply":"2025-06-18T04:03:53.971262Z"}},"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"                                              Prompt  \\\n0  i am a nurse with 2 years of experience in gen...   \n1  i am a nurse with 22 years of experience in ge...   \n2  i am a nurse working in a national referral ho...   \n3  i am a nurse working in a dispensaries and pri...   \n4  i am a nurse working in a health centres in ka...   \n\n                                  generated_response  \n0                                         bronchitis  \n1                              to the right nostrils  \n2                          if it’s a serious disease  \n3                                          twitching  \n4  i should just refer this boy and notify the pu...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Prompt</th>\n      <th>generated_response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>i am a nurse with 2 years of experience in gen...</td>\n      <td>bronchitis</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i am a nurse with 22 years of experience in ge...</td>\n      <td>to the right nostrils</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i am a nurse working in a national referral ho...</td>\n      <td>if it’s a serious disease</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>i am a nurse working in a dispensaries and pri...</td>\n      <td>twitching</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>i am a nurse working in a health centres in ka...</td>\n      <td>i should just refer this boy and notify the pu...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":55},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}